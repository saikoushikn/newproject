"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.ConvertContext = void 0;
/*
 * Copyright (c) 2020, salesforce.com, inc.
 * All rights reserved.
 * Licensed under the BSD 3-Clause license.
 * For full license text, see LICENSE.txt file in the repo root or https://opensource.org/licenses/BSD-3-Clause
 */
const node_path_1 = require("node:path");
const ts_types_1 = require("@salesforce/ts-types");
const core_1 = require("@salesforce/core");
const kit_1 = require("@salesforce/kit");
const common_1 = require("../common");
const collections_1 = require("../collections");
const resolve_1 = require("../resolve");
const streams_1 = require("./streams");
const messages = new core_1.Messages('@salesforce/source-deploy-retrieve', 'sdr', new Map([["md_request_fail", "Metadata API request failed: %s"], ["error_convert_invalid_format", "Invalid conversion format '%s'"], ["error_could_not_infer_type", "%s: Could not infer a metadata type"], ["error_unexpected_child_type", "Unexpected child metadata [%s] found for parent type [%s]"], ["noParent", "Could not find parent type for %s (%s)"], ["error_expected_source_files", "%s: Expected source files for type '%s'"], ["error_failed_convert", "Component conversion failed: %s"], ["error_merge_metadata_target_unsupported", "Merge convert for metadata target format currently unsupported"], ["error_missing_adapter", "Missing adapter '%s' for metadata type '%s'"], ["error_missing_transformer", "Missing transformer '%s' for metadata type '%s'"], ["error_missing_type_definition", "Missing metadata type definition in registry for id '%s'."], ["error_missing_child_type_definition", "Type %s does not have a child type definition %s."], ["noChildTypes", "No child types found in registry for %s (reading %s at %s)"], ["error_no_metadata_xml_ignore", "Metadata xml file %s is forceignored but is required for %s."], ["noSourceIgnore", "%s metadata types require source files, but %s is forceignored."], ["noSourceIgnore.actions", "- Metadata types with content are composed of two files: a content file (ie MyApexClass.cls) and a -meta.xml file (i.e MyApexClass.cls-meta.xml). You must include both files in your .forceignore file. Or try appending \u201C\\*\u201D to your existing .forceignore entry.\n\nSee <https://developer.salesforce.com/docs/atlas.en-us.sfdx_dev.meta/sfdx_dev/sfdx_dev_exclude_source.htm> for examples"], ["error_path_not_found", "%s: File or folder not found"], ["noContentFound", "SourceComponent %s (metadata type = %s) is missing its content file."], ["noContentFound.actions", ["Ensure the content file exists in the expected location.", "If the content file is in your .forceignore file, ensure the meta-xml file is also ignored to completely exclude it."]], ["error_parsing_xml", "SourceComponent %s (metadata type = %s) does not have an associated metadata xml to parse"], ["error_expected_file_path", "%s: path is to a directory, expected a file"], ["error_expected_directory_path", "%s: path is to a file, expected a directory"], ["error_directory_not_found_or_not_directory", "%s: path is not a directory"], ["error_no_directory_stream", "%s doesn't support readable streams on directories."], ["error_no_source_to_deploy", "No source-backed components present in the package."], ["error_no_components_to_retrieve", "No components in the package to retrieve."], ["error_static_resource_expected_archive_type", "A StaticResource directory must have a content type of application/zip or application/jar - found %s for %s."], ["error_static_resource_missing_resource_file", "A StaticResource must have an associated .resource file, missing %s.resource-meta.xml"], ["error_no_job_id", "The %s operation is missing a job ID. Initialize an operation with an ID, or start a new job."], ["invalid_xml_parsing", "error parsing %s due to:\\n message: %s\\n line: %s\\n code: %s"], ["zipBufferError", "Zip buffer was not created during conversion"], ["undefinedComponentSet", "Unable to construct a componentSet. Check the logs for more information."], ["replacementsFileNotRead", "The file \"%s\" specified in the \"replacements\" property of sfdx-project.json could not be read."], ["unsupportedBundleType", "Unsupported Bundle Type: %s"], ["filePathGeneratorNoTypeSupport", "Type not supported for filepath generation: %s"], ["missingFolderType", "The registry has %s as is inFolder but it does not have a folderType"], ["tooManyFiles", "Multiple files found for path: %s."], ["cantGetName", "Unable to calculate fullName from path: %s (%s)"], ["missingMetaFileSuffix", "The metadata registry is configured incorrectly for %s. Expected a metaFileSuffix."], ["uniqueIdElementNotInRegistry", "No uniqueIdElement found in registry for %s (reading %s at %s)."], ["uniqueIdElementNotInChild", "The uniqueIdElement %s was not found the child (reading %s at %s)."], ["suggest_type_header", "A metadata type lookup for \"%s\" found the following close matches:"], ["suggest_type_did_you_mean", "-- Did you mean \".%s%s\" instead for the \"%s\" metadata type?"], ["suggest_type_more_suggestions", "Additional suggestions:\nConfirm the file name, extension, and directory names are correct. Validate against the registry at:\n<https://github.com/forcedotcom/source-deploy-retrieve/blob/main/src/registry/metadataRegistry.json>\n\nIf the type is not listed in the registry, check that it has Metadata API support via the Metadata Coverage Report:\n<https://developer.salesforce.com/docs/metadata-coverage>\n\nIf the type is available via Metadata API but not in the registry\n\n- Open an issue <https://github.com/forcedotcom/cli/issues>\n- Add the type via PR. Instructions: <https://github.com/forcedotcom/source-deploy-retrieve/blob/main/contributing/metadata.md>"]]));
class ConvertTransactionFinalizer {
}
/**
 * Merges child components that share the same parent in the conversion pipeline
 * into a single file.
 */
class RecompositionFinalizer extends ConvertTransactionFinalizer {
    constructor() {
        super(...arguments);
        this.transactionState = new Map();
        // A cache of SourceComponent xml file paths to parsed contents so that identical child xml
        // files are not read and parsed multiple times.
        this.parsedXmlCache = new Map();
    }
    async finalize() {
        return Promise.all(Array.from(this.transactionState.values()).map(async (stateValue) => {
            if (!stateValue.component) {
                throw new Error(`The parent component is missing from the recomposition state entry.  The children are ${stateValue.children
                    ?.toArray()
                    .map((c) => c.fullName)
                    .join(', ')}`);
            }
            const recomposedXmlObj = await this.recompose(stateValue.children, stateValue.component);
            return {
                component: stateValue.component,
                writeInfos: [
                    {
                        source: new streams_1.JsToXml(recomposedXmlObj),
                        output: (0, node_path_1.join)(stateValue.component.type.directoryName, `${stateValue.component.fullName}.${stateValue.component.type.suffix}`),
                    },
                ],
            };
        }));
    }
    async recompose(children = new collections_1.ComponentSet(), parent) {
        // When recomposing children that are non-decomposed, read and cache the parent XML to prevent
        // reading the parent source file (referenced in all child SourceComponents) multiple times.
        let parentXml;
        if (parent.type.strategies?.transformer === "nonDecomposed" /* TransformerStrategy.NonDecomposed */ && parent.xml) {
            parentXml = await parent.parseXml();
            this.parsedXmlCache.set(parent.xml, parentXml);
        }
        const parentXmlObj = parent.type.strategies?.recomposition === "startEmpty" /* RecompositionStrategy.StartEmpty */
            ? {}
            : parentXml ?? (await parent.parseXml());
        for (const child of children) {
            if (!child.parent) {
                throw messages.createError('noParent', [child.fullName, child.type.name]);
            }
            const { directoryName: groupName } = child.type;
            const { name: parentName } = child.parent.type;
            const childSourceComponent = child;
            let xmlObj;
            if (parentXml) {
                // If the xml file for the child is in the cache, use it. Otherwise
                // read and cache the xml file that contains this child and use it.
                if (childSourceComponent.xml && !this.parsedXmlCache.has(childSourceComponent.xml)) {
                    // TODO: can we safely parallelize this?
                    // eslint-disable-next-line no-await-in-loop
                    this.parsedXmlCache.set(childSourceComponent.xml, await parent.parseXml(childSourceComponent.xml));
                }
                xmlObj = childSourceComponent.parseFromParentXml(this.parsedXmlCache.get((0, ts_types_1.ensureString)(childSourceComponent.xml, `Child component ${child.fullName} has no xml file`)));
            }
            else {
                // TODO: can we safely parallelize this?
                // eslint-disable-next-line no-await-in-loop
                xmlObj = await childSourceComponent.parseXml();
            }
            if (!xmlObj) {
                throw messages.createError('error_parsing_xml', [child.fullName, child.type.name]);
            }
            const childContents = xmlObj[child.type.name] ?? xmlObj;
            if (!parentXmlObj[parentName]) {
                parentXmlObj[parentName] = { [common_1.XML_NS_KEY]: common_1.XML_NS_URL };
            }
            // type safe way of checking childContents for the key
            if ((0, ts_types_1.getString)(childContents, common_1.XML_NS_KEY)) {
                // child don't need to be written with `xmlns="http://soap.sforce.com/2006/04/metadata"` attribute
                delete childContents[common_1.XML_NS_KEY];
            }
            const parentObj = parentXmlObj[parentName];
            if (!parentObj[groupName]) {
                parentObj[groupName] = [];
            }
            // it might be an object and not an array.  Example: custom object with a Field property containing a single field
            const group = (0, kit_1.ensureArray)(parentObj[groupName]);
            group.push(childContents);
        }
        return parentXmlObj;
    }
}
/** DecompositionStateValue has all props as optional.  The makes writeInfo and origin required  */
const hasFullDecompositionInfo = (value) => Boolean(value[1].writeInfo) && Boolean(value[1].origin);
/**
 * Creates write infos for any children that haven't been written yet. Children may
 * delay being written in order to find potential existing children to merge
 * with in the conversion pipeline.
 */
class DecompositionFinalizer extends ConvertTransactionFinalizer {
    constructor() {
        super(...arguments);
        this.transactionState = new Map();
    }
    // eslint-disable-next-line @typescript-eslint/require-await
    async finalize() {
        return Array.from(this.transactionState.entries())
            .filter(hasFullDecompositionInfo)
            .filter(([, value]) => !value.foundMerge)
            .map(([, value]) => ({ component: value.origin?.parent ?? value.origin, writeInfos: [value.writeInfo] }));
    }
}
/**
 * Merges child components that share the same parent in the conversion pipeline
 * into a single file.
 *
 * Inserts unclaimed child components into the parent that belongs to the default package
 */
class NonDecompositionFinalizer extends ConvertTransactionFinalizer {
    constructor() {
        super(...arguments);
        this.transactionState = {
            childrenByUniqueElement: new Map(),
            exampleComponent: undefined,
        };
        // filename => (childName => childXml)
        this.mergeMap = new Map();
        // filename => sourceComponent
        this.parentComponentMap = new Map();
    }
    async finalize(defaultDirectory, tree = new resolve_1.NodeFSTreeContainer()) {
        const writerData = [];
        if (this.transactionState.childrenByUniqueElement.size === 0) {
            return writerData;
        }
        this.tree = tree;
        const packageDirectories = core_1.SfProject.getInstance(defaultDirectory).getPackageDirectories();
        const pkgPaths = packageDirectories.map((pkg) => pkg.fullPath);
        // nondecomposed metadata types can exist in multiple locations under the same name
        // so we have to find all components that could potentially match inbound components
        if (!this.transactionState.exampleComponent) {
            throw new Error('No example component exists in the transaction state for nondecomposed metadata');
        }
        const allNonDecomposed = pkgPaths.includes(defaultDirectory)
            ? this.getAllComponentsOfType(pkgPaths, this.transactionState.exampleComponent.type.name)
            : // defaultDirectory isn't a package, assume it's the target output dir for conversion so don't scan folder
                [];
        // prepare 3 maps to simplify component merging
        await this.initMergeMap(allNonDecomposed);
        this.parentComponentMap = new Map(allNonDecomposed.map((c) => [(0, ts_types_1.ensureString)(c.xml, `no xml file path for ${c.fullName}`), c]));
        const childNameToParentFilePath = this.initChildMapping();
        // we'll merge any new labels into the default location
        const defaultKey = (0, node_path_1.join)(defaultDirectory, getDefaultOutput(this.transactionState.exampleComponent));
        this.ensureDefaults(defaultKey);
        // put the incoming components into the mergeMap.  Keep track of any files we need to write
        const filesToWrite = new Set();
        this.transactionState.childrenByUniqueElement.forEach((child, childUniqueElement) => {
            const parentKey = childNameToParentFilePath.get(childUniqueElement) ?? defaultKey;
            const parentItemMap = this.mergeMap.get(parentKey);
            parentItemMap?.set(childUniqueElement, child);
            filesToWrite.add(parentKey);
        });
        // use the mergeMap to return the writables
        this.mergeMap.forEach((children, parentKey) => {
            if (filesToWrite.has(parentKey)) {
                const parentSourceComponent = this.parentComponentMap.get(parentKey);
                if (!parentSourceComponent) {
                    throw new Error(`No source component found for ${parentKey}`);
                }
                const recomposedXmlObj = recompose(children, parentSourceComponent);
                writerData.push({
                    component: parentSourceComponent,
                    writeInfos: [{ source: new streams_1.JsToXml(recomposedXmlObj), output: parentKey }],
                });
            }
        });
        return writerData;
    }
    initChildMapping() {
        const output = new Map();
        this.mergeMap.forEach((children, parentKey) => {
            children.forEach((child, childName) => {
                output.set(childName, parentKey);
            });
        });
        return output;
    }
    /**
     * check both top-level maps and make sure there are defaults
     */
    ensureDefaults(defaultKey) {
        if (!this.mergeMap.has(defaultKey)) {
            // If project has no files of this type, there won't be anything from allNonDecomposed.
            this.mergeMap.set(defaultKey, new Map());
        }
        if (!this.parentComponentMap.has(defaultKey)) {
            // it's possible to get here if there are no files of this type in the project.
            // we don't have any SourceComponent to reference except the new incoming ones
            // so this creates a "default" component with the correct path for the xml file
            this.parentComponentMap.set(defaultKey, {
                ...this.transactionState.exampleComponent,
                xml: defaultKey,
            });
        }
    }
    /**
     * Returns all the components of the incoming type in the project.
     *
     * Some components are not resolved during component resolution.
     * This typically only happens when a specific source path was resolved. This is problematic for
     * nondecomposed metadata types (like CustomLabels) because we need to know the location of each
     * child type before recomposing the final xml.
     * The labels could belong in any of the files OR need to go in the default location which already contains labels
     */
    getAllComponentsOfType(pkgDirs, componentType) {
        const unprocessedComponents = collections_1.ComponentSet.fromSource({
            fsPaths: pkgDirs,
            include: new collections_1.ComponentSet([{ fullName: '*', type: componentType }]),
            tree: this.tree,
        }).getSourceComponents();
        return unprocessedComponents.toArray();
    }
    /**
     * Populate the mergeMap with all the children of all the local components
     */
    async initMergeMap(allComponentsOfType) {
        // A function we can parallelize since we have to parseXml for each local file
        const getMappedChildren = async (component) => {
            const results = await Promise.all(component.getChildren().map(async (child) => {
                const childXml = await child.parseXml();
                return [
                    (0, ts_types_1.getString)(childXml, (0, ts_types_1.ensureString)(child.type.uniqueIdElement), `No uniqueIdElement exists in the registry for ${child.type.name}`),
                    childXml,
                ];
            }));
            return new Map(results);
        };
        const result = await Promise.all(allComponentsOfType.map(async (c) => [
            (0, ts_types_1.ensureString)(c.xml, `Missing xml file for ${c.type.name}`),
            await getMappedChildren(c),
        ]));
        this.mergeMap = new Map(result);
    }
}
/**
 * A state manager over the course of a single metadata conversion call.
 */
class ConvertContext {
    constructor() {
        this.decomposition = new DecompositionFinalizer();
        this.recomposition = new RecompositionFinalizer();
        this.nonDecomposition = new NonDecompositionFinalizer();
    }
    // eslint-disable-next-line @typescript-eslint/require-await
    async *executeFinalizers(defaultDirectory) {
        for (const member of Object.values(this)) {
            if (member instanceof ConvertTransactionFinalizer) {
                yield member.finalize(defaultDirectory);
            }
        }
    }
}
exports.ConvertContext = ConvertContext;
/**
 * Return a json object that's built up from the mergeMap children
 */
const recompose = (children, parentSourceComponent) => {
    // for CustomLabels, that's `labels`
    const groupName = parentSourceComponent.type.directoryName;
    return {
        [parentSourceComponent.type.name]: {
            [common_1.XML_NS_KEY]: common_1.XML_NS_URL,
            [groupName]: Array.from(children.values()),
        },
    };
};
/**
 * Return the default filepath for new metadata of this type
 */
const getDefaultOutput = (component) => {
    const { fullName } = component;
    const [baseName] = fullName.split('.');
    const output = `${baseName}.${component.type.suffix}${common_1.META_XML_SUFFIX}`;
    return (0, node_path_1.join)(component.getPackageRelativePath('', 'source'), output);
};
//# sourceMappingURL=convertContext.js.map